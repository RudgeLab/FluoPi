{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "This code identifies bacterial colonies from Petri dish time-lapse images and based on the fluorescent signal it is able to compute a characteristic pattern signal for each fluorescent protein. With this information, the code classify each of the identified colonies. \n",
    "\n",
    "##### Requirements\n",
    " - Image data\n",
    " - Have _fluopi_ module installed (open Terminal in Mac or command line in Windows and type  `pip install fluopi`; more info [here](https://packaging.python.org/tutorials/installing-packages/) about installing python packages)\n",
    "\n",
    "\n",
    "## Analysis\n",
    "\n",
    "\n",
    "### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import some useful packages to manage the data\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "# modify some matplotlib parameters to manage the images in illustrator\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the FluoPi module\n",
    "import fluopi.analysis as flua\n",
    "import fluopi.plotting as flup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "In each _pathname_ is the complete path of the folder where images are stored. The example data can be obtained from the **_Files_** section in the [OSF FluoPi proyect](https://osf.io/dy6p2/). There you can download it from the *Google drive/Example_data* folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pathname1 = os.path.abspath('Images/Classifier/sfGFP_data/')\n",
    "#refered to google drive folder Example_data\\Classifier\\sfGFP_data`\n",
    "                      \n",
    "pathname2 = os.path.abspath('Images/Classifier/CyOFP_data/')\n",
    "#refered to google drive folder Example_data\\Classifier\\CyOFP_data\n",
    "\n",
    "pathname3 = os.path.abspath('Images/Classifier/BeRFP_data/')\n",
    "#refered to google drive folder Example_data\\Classifier\\BeRFP_data\n",
    "\n",
    "pathname4 =  os.path.abspath('Images/Classifier/RGO_data/')\n",
    "#refered to google drive folder Example_data\\Classifier\\RGO_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, make the image names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname1 = os.path.join(pathname1, \"image_%04d\"+\".jpg\")\n",
    "                      \n",
    "fname2 = os.path.join(pathname2, \"image_%04d\"+\".jpg\")\n",
    "\n",
    "fname3 = os.path.join(pathname3, \"image_%04d\"+\".jpg\")\n",
    "\n",
    "fname4 =  os.path.join(pathname4, \"image_%04d\"+\".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also save the number name of the last image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lim1=int(os.listdir(pathname1)[-1].split('_')[-1].split('.')[0])\n",
    "lim2=int(os.listdir(pathname2)[-1].split('_')[-1].split('.')[0])\n",
    "lim3=int(os.listdir(pathname3)[-1].split('_')[-1].split('.')[0])\n",
    "lim4=int(os.listdir(pathname4)[-1].split('_')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the data loading and channel structure (e.g. with the last frame image of the second data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbdime-conflicts": {
     "local_diff": [
      {
       "key": "collapsed",
       "op": "add",
       "value": false
      }
     ],
     "remote_diff": [
      {
       "key": "collapsed",
       "op": "add",
       "value": true
      }
     ]
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flup.plot_im_frame(fname2,lim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flup.plt_im_frame_channels(fname2,lim2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the files in each data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imCount1=flua.count_files(pathname1,\"jpg\")\n",
    "imCount2=flua.count_files(pathname2,\"jpg\")\n",
    "imCount3=flua.count_files(pathname3,\"jpg\")\n",
    "imCount4=flua.count_files(pathname4,\"jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we organize the data and split it into the different channels. Also, here you can define with frames of the whole original data you are going to use (i.e. by defining `frame > 1` you can select which data to use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataS1={}\n",
    "frames1 = 10   # use one image every 10 frames\n",
    "DataS1['R'],DataS1['G'],DataS1['B']=flua.get_im_data(frames1,imCount1,fname1)\n",
    "DataS1['Im']=fname1     # to store the related image source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataS2={}\n",
    "frames2 = 5     \n",
    "DataS2['R'],DataS2['G'],DataS2['B']=flua.get_im_data(frames2,imCount2,fname2)\n",
    "DataS2['Im']=fname2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataS3={}\n",
    "frames3 = 5     \n",
    "DataS3['R'],DataS3['G'],DataS3['B']=flua.get_im_data(frames3,imCount3,fname3) \n",
    "DataS3['Im']=fname3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataS4={}\n",
    "frames4 = 5    \n",
    "DataS4['R'],DataS4['G'],DataS4['B']=flua.get_im_data(frames4,imCount4,fname4)\n",
    "DataS4['Im']=fname4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we have each data serie on a dictionary, organized in arrays for each channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Background subtraction\n",
    "First step is to identify a good background area and compute his value over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BG1=flua.bg_value(200,370,10,400,DataS1,imCount1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BG2=flua.bg_value(180,360,420,750,DataS2,imCount2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BG3=flua.bg_value(100,380,50,430,DataS3,imCount3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BG4=flua.bg_value(450,670,260,420,DataS4,imCount4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can subtract this background vector value to each frame on the data to eliminate the background effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataSB1=flua.bg_subst(DataS1,BG1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataSB2=flua.bg_subst(DataS2,BG2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataSB3=flua.bg_subst(DataS3,BG3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataSB4=flua.bg_subst(DataS4,BG4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get colony position\n",
    "A good way to identify where colonies are situated is by summing the value of each pixel for all the channels and all the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SumData1=flua.data_sum_time(DataSB1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SumData2=flua.data_sum_time(DataSB2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SumData3=flua.data_sum_time(DataSB3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SumData4=flua.data_sum_time(DataSB4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Apply a filter to smooth the data \n",
    "This process let us reduce noise and improve border detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sDatS1,sDatSall1,SDatST1=flua.smooth_data(DataSB1,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sDatS2,sDatSall2,SDatST2=flua.smooth_data(DataSB2,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sDatS3,sDatSall3,SDatST3=flua.smooth_data(DataSB3,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sDatS4,sDatSall4,SDatST4=flua.smooth_data(DataSB4,1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blob detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blobD1 = flua.colony_blobs_id(sDatS1['G'],0.35,DataS1['Im']%(lim1-1)) \n",
    "#for green it was better to use only the green channel\n",
    "\n",
    "blobD1 = flua.colony_blobs_id(sDatS1['G'],0.35,DataS1['Im']%(lim1),filename='Plots/Classifier/Blobs_sfGFP') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blobD2 = flua.colony_blobs_id(sDatSall2,0.34,DataS2['Im']%(lim2-1))\n",
    "blobD2 = flua.colony_blobs_id(sDatSall2,0.34,DataS2['Im']%(lim2),filename='Plots/Classifier/Blobs_CyOFP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blobD3 = flua.colony_blobs_id(sDatSall3,0.34,DataS3['Im']%(lim3-1))\n",
    "blobD3 = flua.colony_blobs_id(sDatSall3,0.34,DataS3['Im']%(lim3),filename='Plots/Classifier/Blobs_BeRFP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blobD4 = flua.colony_blobs_id(sDatSall4,0.37,DataS4['Im']%(lim4-1))\n",
    "blobD4 = flua.colony_blobs_id(sDatSall4,0.37,DataS4['Im']%(lim4),filename='Plots/Classifier/Blobs_MixFPs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rois1,RoisC1,NC1 = flua.obtain_rois(DataSB1,blobD1)\n",
    "Rois2,RoisC2,NC2 = flua.obtain_rois(DataSB2,blobD2)\n",
    "Rois3,RoisC3,NC3 = flua.obtain_rois(DataSB3,blobD3)\n",
    "Rois4,RoisC4,NC4 = flua.obtain_rois(DataSB4,blobD4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROIS Color Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChanX='G'\n",
    "ChanY='R'\n",
    "Xchan1,Ychan1=flup.rois_last_frame_2chan_plt(RoisC1,ChanX,ChanY,'Serie sfGFP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xchan2,Ychan2=flup.rois_last_frame_2chan_plt(RoisC2,ChanX,ChanY,'Serie BeRFP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xchan3,Ychan3=flup.rois_last_frame_2chan_plt(RoisC3,ChanX,ChanY,'Serie CyOFP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xchan4,Ychan4=flup.rois_last_frame_2chan_plt(RoisC4,ChanX,ChanY,'Serie Mix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit1=flua.linear_fit(Xchan1[:,0],Ychan1[:,0])\n",
    "fit1=flua.linear_fit(Xchan1[:,0],Ychan1[:,0],filename=\"Plots/Classifier/RG_fit1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit2=flua.linear_fit(Xchan2[:,0],Ychan2[:,0])\n",
    "fit2=flua.linear_fit(Xchan2[:,0],Ychan2[:,0],filename=\"Plots/Classifier/RG_fit2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit3=flua.linear_fit(Xchan3[:,0],Ychan3[:,0])\n",
    "fit3=flua.linear_fit(Xchan3[:,0],Ychan3[:,0],filename=\"Plots/Classifier/RG_fit3.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ClasS4,NClasS4=flua.colony_classifier([fit1,fit2,fit3],['GFP','CyOFP','BeRFP'],Xchan4,Ychan4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmin=0\n",
    "flup.plt_lin_fit(Xmin,90000,fit1,'g')\n",
    "flup.plt_lin_fit(Xmin,90000,fit2,'y')\n",
    "flup.plt_lin_fit(Xmin,30000,fit3,'r')\n",
    "plt.plot(NClasS4['GFP'][0],NClasS4['GFP'][1],'go')\n",
    "plt.plot(NClasS4['CyOFP'][0],NClasS4['CyOFP'][1],'yo')\n",
    "plt.plot(NClasS4['BeRFP'][0],NClasS4['BeRFP'][1],'ro')\n",
    "plt.savefig(\"Plots/Classifier/Classification.pdf\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
